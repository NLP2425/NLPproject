{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3fad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| #      | method           | algorithm           | train   | Test 1                                           | Test 2                                           | Test 3                                           |\n",
      "|--------|------------------|---------------------|---------|--------------------------------------------------|--------------------------------------------------|--------------------------------------------------|\n",
      "| 1.a.i  | Machine learning | SVM                 | train2  | Precision=0.579, Recall=0.608, F1=0.590, Accuracy=0.608 | Precision=0.583, Recall=0.618, F1=0.574, Accuracy=0.618 | Precision=0.526, Recall=0.435, F1=0.366, Accuracy=0.435 |\n",
      "| 1.a.i  | Machine learning | SVM                 | TRAIN   | Precision=0.653, Recall=0.640, F1=0.646, Accuracy=0.640 | Precision=0.617, Recall=0.628, F1=0.619, Accuracy=0.628 | Precision=0.766, Recall=0.739, F1=0.732, Accuracy=0.739 |\n",
      "| 1.b.i  | Machine learning | XGB                 | train2  | Precision=0.585, Recall=0.649, F1=0.591, Accuracy=0.649 | Precision=0.548, Recall=0.602, F1=0.527, Accuracy=0.602 | Precision=0.544, Recall=0.387, F1=0.290, Accuracy=0.387 |\n",
      "| 1.b.i  | Machine learning | XGB                 | TRAIN   | Precision=0.602, Recall=0.652, F1=0.603, Accuracy=0.652 | Precision=0.623, Recall=0.632, F1=0.564, Accuracy=0.632 | Precision=0.677, Recall=0.482, F1=0.428, Accuracy=0.482 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Definicije datoteka\n",
    "train_files = {\n",
    "    \"train2\": [\"train-2.csv\"],\n",
    "    \"TRAIN\": [\"train-1.csv\", \"train-2.csv\", \"train-3.csv\"]\n",
    "}\n",
    "test_files = {\n",
    "    \"Test 1\": \"test-1.csv\",\n",
    "    \"Test 2\": \"test-2.csv\",\n",
    "    \"Test 3\": \"test-3.csv\"\n",
    "}\n",
    "text_column = \"Sentence\"\n",
    "target_column = \"Label\"\n",
    "\n",
    "# Mapiranje labela\n",
    "label_map = {\n",
    "    0: 'positive',\n",
    "    1: 'neutral',\n",
    "    2: 'negative'\n",
    "}\n",
    "\n",
    "# Funkcija za predobradu teksta (bez NLTK-a)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Pretvori u mala slova\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Ukloni sve znakove osim slova, brojeva i razmaka\n",
    "    return text\n",
    "\n",
    "def load_and_filter(files):\n",
    "    if isinstance(files, str):\n",
    "        files = [files]\n",
    "    X_all, y_all = [], []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df = df[df[target_column].isin([0, 1, 2])]\n",
    "        # Predobrada teksta (bez NLTK-a)\n",
    "        texts = [preprocess_text(text) for text in df[text_column].astype(str)]\n",
    "        X_all.extend(texts)\n",
    "        y_all.extend(df[target_column])\n",
    "    return X_all, y_all\n",
    "\n",
    "models = [\n",
    "    ('1.a.i', 'Machine learning', 'SVM', SVC(class_weight='balanced', kernel='rbf', probability=True, random_state=42)),\n",
    "    ('1.b.i', 'Machine learning', 'XGB', GradientBoostingClassifier(random_state=42)),\n",
    "]\n",
    "\n",
    "table = []\n",
    "\n",
    "# Učitaj test skupove jednom\n",
    "X_tests_raw = {}\n",
    "y_tests = {}\n",
    "for test_name, test_file in test_files.items():\n",
    "    X_text, y = load_and_filter(test_file)\n",
    "    X_tests_raw[test_name] = X_text\n",
    "    y_tests[test_name] = y\n",
    "\n",
    "for code, method, algorithm, model in models:\n",
    "    for train_name, train_sources in train_files.items():\n",
    "        # Učitaj train skup\n",
    "        X_train_text, y_train = load_and_filter(train_sources)\n",
    "        # Vektorizacija\n",
    "        vectorizer = TfidfVectorizer(max_features=7000, ngram_range=(1, 4), sublinear_tf=True, norm='l2')\n",
    "        X_train = vectorizer.fit_transform(X_train_text)\n",
    "        # Pripremi test skupove za ovaj vektorizer\n",
    "        X_tests = {name: vectorizer.transform(X_tests_raw[name]) for name in X_tests_raw}\n",
    "        # Treniraj model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Za svaki test skup izračunaj metrike\n",
    "        metrics = []\n",
    "        for test_name in [\"Test 1\", \"Test 2\", \"Test 3\"]:\n",
    "            y_true = y_tests[test_name]\n",
    "            y_pred = model.predict(X_tests[test_name])\n",
    "            precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "            recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            metric_str = f\"Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}, Accuracy={accuracy:.3f}\"\n",
    "            metrics.append(metric_str)\n",
    "        # Dodaj redak u tablicu\n",
    "        row = [code, method, algorithm, train_name] + metrics\n",
    "        table.append(row)\n",
    "\n",
    "# Ispis tablice u markdown formatu\n",
    "header = \"| #      | method           | algorithm           | train   | Test 1                                           | Test 2                                           | Test 3                                           |\"\n",
    "sep    = \"|--------|------------------|---------------------|---------|--------------------------------------------------|--------------------------------------------------|--------------------------------------------------|\"\n",
    "print(\"\\n\" + header)\n",
    "print(sep)\n",
    "for row in table:\n",
    "    print(f\"| {row[0]:<6} | {row[1]:<16} | {row[2]:<19} | {row[3]:<7} | {row[4]:<48} | {row[5]:<48} | {row[6]:<48} |\")\n",
    "\n",
    "with open('results.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(header + \"\\n\")\n",
    "    f.write(sep + \"\\n\")\n",
    "    for row in table:\n",
    "        f.write(f\"| {row[0]:<6} | {row[1]:<16} | {row[2]:<19} | {row[3]:<7} | {row[4]:<48} | {row[5]:<48} | {row[6]:<48} |\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
